# -*- coding: utf-8 -*-
"""Copy of MISM_6212_Team10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12V8YbC2r4I8_Ittro33H5WCzqShCDje2

## Business Question:
We aim to explore the relationship between lifestyle choices, physical health indicators, and the risk of diabetes. In particular, we will analyze factors such as physical activity, smoking, alcohol consumption, BMI, and other health indicators correlate with diabetes risk. Beside that, we will consider building a predictive model to identify individuals who are at high risk of developing diabetes based on these health indicators.

Diabetes is a significant public health concern, and early detection of risk factors can help preventative healthcare initiatives. Therefore, we hope that our findings could help public health organizations/medical professionals strategize diabetes educational initiatives and clinical decision making better while supporting patients to mitigate their diabetes risks or manage this disease more effectively.

## Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind, t
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from IPython.display import Markdown
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.neural_network import MLPClassifier
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier

"""## Data Accessing & Wrangling"""

df = pd.read_csv('diabetes_health_indicators.csv')

df

df.shape

"""### Data Structure Assessment"""

df.info()

"""#### Data Descriptions:
|  Column                                        | Description  
|  :------                                       |   -----:
|  Diabetes_012                                  |  0 = no diabetes; 1 = prediabetes; 2 = diabetes   
|  HighBP                                        |  0 = no high Blood Pressure; 1 = high Blood Pressure
|  HighChol                                      |  0 = no high Cholesterol; 1 = high Cholesterol
|  CholCheck                                     |  0 = no cholesterol check in 5 years; <br> 1 = yes cholesterol check in 5 years
|  BMI                                           |  Body Mass Index
|  Smoker                                        |  Have you smoked at least 100 cigarettes in your entire life? <br> 0 = no ; 1 = yes
|  Stroke                                        |  (Ever told) you had a stroke? 0 = no; 1 = yes
|  HeartDiseaseorAttack                          |  Coronary Heart Disease (CHD) <br> or Myocardial Infarction (MI)? <br> 0 = no; 1 = yes  
|  PhysActivity                                  |  Physical activity in past 30 days - not including job? <br> 0 = no; 1 = yes
|  Fruits                                        |  Consume Fruit 1 or more times per day? <br> 0 = no; 1 = yes  
|  Veggies                                       |  Consume Vegetables 1 or more times per day? <br> 0 = no; 1 = yes
|  HvyAlcoholConsump                             |  Heavy drinkers ( men more than 14 drinks per week <br> or women more than 7 drinks per week)? <br> 0 = no; 1 = yes  
|  AnyHealthcare                                 |   Have any kind of health care coverage? <br> 0 = no; 1 = yes
|  NoDocbcCost                                   |  Was there a time in the past 12 months when you needed <br> to see a doctor but could not because of cost? <br> 0 = no; 1 = yes
|  GenHlth                                       |  Would you say that in general your health on scale 1-5 is: <br> 1 = excellent, 2 = very good, <br> 3 = good. 4 = fair, 5 = poor
|  MentHlth.                                     |  For how many days during the past 30 days was your <br> mental health not good? <br> scale 1-30 days  
| PhysHlth                                       |  For how many days during the past 30 days was your <br> physical health not good? <br> scale 1-30 days
| DiffWalk                                       |  Do you have serious difficulty walking or climbing stairs? <br> 0 = no; 1 = yes
| Sex                                            | 0 = female; 1 = male
| Age                                            | 1 = 18-24 y/o; 2 = 25-29; 3 = 30-34; <br> 4 = 35-39; 5 = 40-44; 6 = 45-49; <br> 7 = 50-54; 8 = 55-59; 9 = 60-64; 10 = 65-69; <br> 11 = 70-74; 12 = 75-79; 13 = 80 or older
| Education                                      | 1 = Never attended school or only kindergarten; 2 = Grades 1-8; <br> 3 = Grades 9-11; 4 = Grade 12 or GED (High school graduate); <br> 5 = College 1-3 years (Some college or technical school); <br> 6 = College 4 years or more
| Income                                         | 1 = less than 10,000; 2 = less than 15,000; <br> 3 = less than 20,000; 4 = less than 25,000; <br> 5 = less than 35,000; 6 = less than 50,000; <br> 7 = less than 75,000; 8 = 75,000 or more.

### Data Transformation
"""

# For machine learning purpose, we will convert Diabetes variable to binary with
# 0 = no diabetes and 1 = prediabetes/diabetes
df['Diabetes_012'] = df['Diabetes_012'].replace(2, 1)
df = df.rename(columns={'Diabetes_012':'Diabetes_binary'})

df['Diabetes_binary'].value_counts()

# Converting binary variables from float to int64
binary_vars = ['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost','DiffWalk', 'Sex']
for var in binary_vars:
    df[var] = df[var].astype('int64')

# Converting categorical variables from float to category dtype
category_vars = ['Age', 'Education', 'Income','GenHlth']
for var in category_vars:
   df[var] = df[var].astype('category')

# Converting time-based variables from float to integer
df['MentHlth'] = df['MentHlth'].astype('int64')
df['PhysHlth'] = df['PhysHlth'].astype('int64')

df.info()

"""### Checking Missing Values, Unique Values and Duplicates"""

df.isnull().sum()

# Print unique values
cols = df.columns
for col in cols:
    print(col)

    # get a list of unique values
    unique = df[col].unique()
    print(unique, '\n====================================\n\n')

duplicates = df[df.duplicated()]
print(f"Number of Duplicates: {len(duplicates)}")

duplicates

"""Explanation for keeping duplicates: Since our dataset is deprived from a public survey generated by the Center for Diseases Control and Prevention, it contains over 100 variables. For the purpose of this Machine Learning project, we only utilize a subset of this survey data with the most relevant variables in predicting diabetes risk. Therefore, there is a possibility that a significant number of records share similar clinical profiles, making them become duplicates. We will keep these duplicates as removing them entirely will cause discrepancies in our model(s).

## Exploratory Data Analysis

### Statistical Summary

#### Statistical Measures
"""

#Copy the dataset for EDA to avoid modifying the original dataframe (as requested)
df_eda = df.copy()

# Statistical Summary of Numerical Variables
# This will display key statistics like mean, standard deviation, quartiles, and skewness
# Skewness helps detect asymmetric distributions (right/left skew)

numeric_cols = df_eda.select_dtypes(include=['int64', 'float64']).columns
stat_summary = df_eda[numeric_cols].describe().T
stat_summary['Skewness'] = df_eda[numeric_cols].skew()
stat_summary
# Key findings:
# BMI and Physical Health Days are right-skewed, meaning many individuals have low values, but a few have very high values
# Some variables (e.g., HighBP, HighChol) are binary (0 or 1)
# Diabetes cases (1s) are less frequent than non-diabetic cases (0s)

"""#### Outlier Analysis"""

# Outlier Detection using the Interquartile Range (IQR) method
# Outliers are values significantly higher or lower than the majority of data
# The IQR method detects extreme values in BMI, Mental Health Days, and Physical Health Days

outlier_info = {}
for col in ['BMI', 'MentHlth', 'PhysHlth']:
    Q1 = df_eda[col].quantile(0.25)
    Q3 = df_eda[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df_eda[(df_eda[col] < lower_bound) | (df_eda[col] > upper_bound)]
    outlier_info[col] = len(outliers)
outlier_info
# Key Findings:
# Many individuals have extremely high BMI (40+), indicating obesity related health risks
# Some individuals reported 30 days of poor mental/physical health, which may indicate chronic conditions

"""### Univariate Analysis

#### Distribution Plots (Histograms) and Box Plots (Outliers and Spread)
"""

# Univariate Analysis: Histograms and Boxplots
# Histograms show distributions of continuous variables
# Boxplots highlight outliers and spread of variables

fig, axes = plt.subplots(2, 3, figsize=(18, 12))
sns.histplot(df_eda['BMI'], bins=30, kde=True, ax=axes[0, 0]).set_title("Histogram of BMI")
sns.histplot(df_eda['Age'].cat.codes, bins=30, kde=True, ax=axes[0, 1]).set_title("Histogram of Age")
sns.histplot(df_eda['PhysHlth'], bins=30, kde=True, ax=axes[0, 2]).set_title("Histogram of Physical Health Days")

sns.boxplot(x=df_eda['BMI'], ax=axes[1, 0]).set_title("Boxplot of BMI")
sns.boxplot(x=df_eda['MentHlth'], ax=axes[1, 1]).set_title("Boxplot of Mental Health Days")
sns.boxplot(x=df_eda['PhysHlth'], ax=axes[1, 2]).set_title("Boxplot of Physical Health Days")

plt.tight_layout()
plt.show()

# Key Findings:
# BMI is right-skewed with many individuals in the overweight/obese range
# Physical Health Days shows a large number of outliers at 30 days (chronic illness)
# Age distribution suggests more older individuals than younger ones in the dataset

"""#### Count Plots (Categorical Variables)"""

# Count Plots for Categorical Variables
# Count plots show the distribution of categorical variables.
# This helps identify imbalances** (e.g., more smokers vs. non-smokers).

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
sns.countplot(x=df_eda['Smoker'], ax=axes[0]).set_title("Count of Smokers vs. Non-Smokers")
sns.countplot(x=df_eda['Diabetes_binary'], ax=axes[1]).set_title("Count of Diabetes Cases")
sns.countplot(x=df_eda['HighBP'], ax=axes[2]).set_title("Count of High Blood Pressure Cases")

plt.tight_layout()
plt.show()

# Key Findings:
# Smoking: More non-smokers than smokers.
# Diabetes: Fewer individuals have diabetes (1s) than those without (0s), suggesting an imbalance in the target variable.
# High Blood Pressure (Hypertension): A significant number of individuals have high blood pressure (1s), which could be a risk factor for diabetes.

# Bivariate Analysis: Scatter Plots to check relationships between variables
# These plots help determine if two variables have any relationship.
# Scatter plot: BMI vs. Diabetes Status

plt.figure(figsize=(8, 5))
sns.scatterplot(x=df_eda['BMI'], y=df_eda['Diabetes_binary'], alpha=0.3)
plt.xlabel("BMI")
plt.ylabel("Diabetes (0 = No, 1 = Yes)")
plt.title("Scatter Plot of BMI vs. Diabetes Status")
plt.show()

# Key Findings:
# No strong trend is visible
# Higher BMI values appear in both diabetic and non-diabetic groups, suggesting BMI alone is not a perfect predictor of diabetes

# Scatter plot: Age vs. BMI
plt.figure(figsize=(8, 5))
sns.scatterplot(x=df_eda['Age'].cat.codes, y=df_eda['BMI'], alpha=0.3)
plt.xlabel("Age (Encoded)")
plt.ylabel("BMI")
plt.title("Scatter Plot of Age vs. BMI")
plt.show()

# Key Findings:
# BMI is widely distributed across all age groups.
# There is no strong correlation between age and BMI.

# Scatter plot: Physical Health Days vs. Diabetes Status
plt.figure(figsize=(8, 5))
sns.scatterplot(x=df_eda['PhysHlth'], y=df_eda['Diabetes_binary'], alpha=0.3)
plt.xlabel("Physical Health Days (Past 30 days)")
plt.ylabel("Diabetes (0 = No, 1 = Yes)")
plt.title("Scatter Plot of Physical Health Days vs. Diabetes Status")
plt.show()

#Key findings:
# A noticeable subset of individuals reporting 30 days of poor physical health appear in both diabetic and non-diabetic groups, suggesting chronic physical health issues are not exclusive to diabetes patients.
# Many individuals with diabetes reported 0 poor physical health days, indicating that diabetes does not always correlate with reported physical health distress.
# No clear trend is visible between physical health days and diabetes, implying that other factors such as: BMI, age, blood pressure, may play a more significant role in diabetes risk

# Scatter plot: Mental Health Days vs. Diabetes Status
plt.figure(figsize=(8, 5))
sns.scatterplot(x=df_eda['MentHlth'], y=df_eda['Diabetes_binary'], alpha=0.3)
plt.xlabel("Mental Health Days (Past 30 days)")
plt.ylabel("Diabetes (0 = No, 1 = Yes)")
plt.title("Scatter Plot of Mental Health Days vs. Diabetes Status")
plt.show()

#Key Findings:
# A subset of individuals reporting 30 days of poor mental health appear in both diabetic and non diabetic groups, suggesting that chronic mental distress is not exclusive to diabetes patients.
# Many individuals with diabetes reported 0 poor mental health days, indicating that mental health issues are not necessarily linked to diabetes.
# No clear trend is visible between mental health days and diabetes, implying that other factors such as: BMI, physical health, blood pressure, may play a more significant role in diabetes risk.

# Display the statistical summary to analyze numerical data
# Statistical summary
from IPython.display import display
display(stat_summary)

#Print outlier information to identify extreme values
print("Outlier Counts:", outlier_info)

"""### Multivariate Analysis

#### Correlation Heatmap
"""

correlation_matrix = df.corr()

plt.figure(figsize=(15, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap')
plt.show()

"""Key Findings:
* Multifactorial Nature of Diabetes: The Diabetes_binary variable does not strongly correlate with any single predictor (|r| < 0.2 for most), suggesting diabetes risk results from multiple risk factors acting jointly rather than one dominant factor.
* Absence of Strong Collinearity: Most features fall in the −0.2 to 0.2 correlation range with each other. This low collinearity is promising for model stability—no single pair of features is redundant, and we likely retain valuable information by including multiple predictors.
* Moderate Correlations: A few variable pairs stand out (correlation ≈ 0.5). For instance:
-- DiffWalk vs. PhysHlth: Participants with serious difficulty walking also tend to report more days of poor physical health.
-- GenHlth vs. PhysHlth: Deteriorating physical health is strongly associated with poorer self-rated general health.
-- GenHlth vs. DiffWalk: Lower general health ratings align with walking difficulties, reinforcing how functional limitations and self-perceived health often co-occur.

### Target-Based Analysis

#### Health Indicators and Diabetes

##### BMI and Diabetes Risk
"""

bmi_df = df.copy()

bmi_df['BMI_Category'] = bmi_df['BMI'].apply(lambda x: 'Underweight' if x < 18.5 else ('Normal' if x < 25 else ('Overweight' if x < 30 else 'Obese')))

plt.figure()
sns.barplot(
    data=bmi_df,
    x='BMI_Category',
    y='Diabetes_binary',
    estimator=lambda x: x.mean(),
    errorbar=('ci', 95),
    palette='Set1')

plt.title('Proportion of Individuals with Diabetes by BMI Category')
plt.xlabel('BMI Category')
plt.ylabel('Proportion with Diabetes')
plt.ylim(0, 1)
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='Diabetes_binary', y='BMI', data=df, palette='Set1')
plt.title('BMI Distribution by Diabetes Status')
plt.xlabel('Diabetes Status')
plt.xticks([0, 1], ['No Diabetes', 'Pre-Diabetes/Diabetes'])
plt.ylabel('BMI')
plt.show()

# Conducting hypothesis test to determine if the differences of average BMI between 2 groups
# are statistically significant
print("H0: μBMI_No_Diabetes = μBMI_Diabetes | Ha: μBMI_No_Diabetes =/= μBMI_Diabetes")
diabetes_group = df[df['Diabetes_binary'] == 1]['BMI']
no_diabetes_group = df[df['Diabetes_binary'] == 0]['BMI']

# Descriptive Statistics
bmi_mean_diabetes = diabetes_group.mean()
bmi_mean_no_diabetes = no_diabetes_group.mean()
print(f"μBMI_No_Diabetes = {bmi_mean_no_diabetes:.2f}")
print(f"μBMI_Diabetes = {bmi_mean_diabetes:.2f}")

# T critical value:
deg_of_freedom = len(diabetes_group) + len(no_diabetes_group) - 2
t_critical = t.ppf(1 - 0.05, deg_of_freedom)

print(f"Degree of Freedom: {deg_of_freedom} | alpha = 0.05 ")
print(f"T-Critical Value: {t_critical}")

# Perform a two-sample t-test (assuming unequal variances)
t_stat, p_value = ttest_ind(diabetes_group, no_diabetes_group, equal_var=False)
print(f"T-test: t={t_stat:.2f}, p={p_value:.3f}")
# Interpretation

if p_value < 0.05:
    print("Conclusion: Reject null hypothesis. There is sufficient evidence to conclude that the the average BMI of people without diabetes is different than people with diabetes.")
else:
    print("Conclusion: Do not reject null hypothesis.There is not sufficient evidence to conclude that the the average BMI of people without diabetes is different than people with diabetes.")

"""* Statistically Significant Difference: The two-sample t-test (p < 0.05) shows that individuals with diabetes have a higher mean BMI (31.80) than those without (27.74).
* Clinical & Practical Implications: Obesity remains a key modifiable risk factor. As BMI climbs above 25 (Overweight) and above 30 (Obese), the prevalence of diabetes rises sharply.

##### Blood Pressure
"""

bp_diabetes_ct = pd.crosstab(df['HighBP'], df['Diabetes_binary'])
bp_prop_table = bp_diabetes_ct.div(bp_diabetes_ct.sum(axis=1), axis=0)
bp_prop_table.plot(kind='bar', stacked=True, colormap='Set3')
plt.title('Proportion of Diabetes Status by Blood Pressure Level')
plt.xlabel('Blood Pressure')
plt.ylabel('Proportion')
plt.xticks([0, 1], ['No High Blood Pressure', 'High Blood Pressure'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""##### Roughly 25% of people with high blood pressure also have diabetes or prediabetes. Given the well-documented synergy between hypertension and insulin resistance, this is an important cluster to monitor.

##### Cholesterol
"""

chol_diabetes_ct = pd.crosstab(df['HighChol'], df['Diabetes_binary'])
chol_prop_table = chol_diabetes_ct.div(chol_diabetes_ct.sum(axis=1), axis=0)
chol_prop_table.plot(kind='bar', stacked=True, colormap='Set3')
plt.title('Proportion of Diabetes Status by Cholesterol Level')
plt.xlabel('Cholesterol Level')
plt.ylabel('Proportion')
plt.xticks([0, 1], ['No High Cholesterol', 'High Cholesterol'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

chol_df = df.copy()
chol_df['Cholesterol Factor'] = chol_df.apply(lambda row: 'High Chol & Checked' if row['HighChol'] == 1 and row['CholCheck'] == 1
                                      else ('High Chol but Not Check' if row['HighChol'] == 1 else
                                       ('No High Chol but Checked' if row['CholCheck'] == 1 else 'No High Chol & Not Check')), axis=1)

chol_ct = pd.crosstab(chol_df['Cholesterol Factor'], chol_df['Diabetes_binary'])

chol_prop_ct = chol_ct.div(chol_ct.sum(axis=1), axis=0)

chol_prop_ct.plot(kind='bar', stacked=True, figsize=(8,4), colormap='Set3')
plt.title('Proportion of Diabetes by Cholesterol Levels & Check Up in Past 5 Years')
plt.xlabel('Cholesterol Factors')
plt.ylabel('Proportion')
plt.legend(title='Diabetes Status', labels=['No Diabetes', 'Diabetes'], loc='lower right')
plt.show()

"""Among those with high cholesterol who had it checked, ~25% have diabetes. Interestingly, even among those who don’t have high cholesterol and do not check it, ~10% are diabetic—implying lack of screening does not preclude risk."""

heartdisease_diabetes_ct = pd.crosstab(df['HeartDiseaseorAttack'], df['Diabetes_binary'])
heart_prop_table = heartdisease_diabetes_ct.div(heartdisease_diabetes_ct.sum(axis=1), axis=0)
heart_prop_table.plot(kind='bar', stacked=True, colormap='Set3')
plt.title('Proportion of Diabetes Status by Heart Disease or Attack')
plt.xlabel('Heart Disease or Attack')
plt.ylabel('Proportion')
plt.xticks([0,1],['Has CHD or MI', 'No CHD or MI'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""About 30% of participants without heart disease still have pre/diabetes. Although heart disease and diabetes often co-occur, the large fraction without heart disease suggests diabetes frequently presents without overt cardiovascular events—highlighting the importance of proactive screening."""

stroke_diabetes_ct = pd.crosstab(df['Stroke'], df['Diabetes_binary'])
stroke_prop_table = stroke_diabetes_ct.div(stroke_diabetes_ct.sum(axis=1), axis=0)
stroke_prop_table.plot(kind='bar', stacked=True, colormap='Set3')
plt.title('Proportion of Diabetes Status by Stroke Risk')
plt.xlabel('Stroke Risk')
plt.ylabel('Proportion')
plt.xticks([0,1],['Has Stroke', 'No Stroke'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""About 30% of people who do not have Stroke have prediabetes/diabetes. Stroke is often a downstream consequence of long-term uncontrolled diabetes and other cardiovascular issues. The fact that a significant portion of people without stroke still exhibit prediabetes/diabetes suggests that diabetes can be present well before severe complications like stroke develop. This supports the importance of early detection and intervention.



"""

gender_diabetes_ct = pd.crosstab(df['Sex'], df['Diabetes_binary'])
gender_prop_table = gender_diabetes_ct.div(gender_diabetes_ct.sum(axis=1), axis=0)
gender_prop_table.plot(kind='bar', stacked=True, colormap='Set3')
plt.title('Proportion of Diabetes Status by Gender')
plt.xlabel('Gender')
plt.ylabel('Proportion')
plt.xticks([0,1],['Female', 'Male'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""##### Males and females show similar ~18% prevalence of pre/diabetes. This parity suggests that gender alone is not a strong differentiator; future analysis might look at whether lifestyle factors differ by gender.

#### Social Determinants of Health and Diabetes
"""

age_diabetes_ct = pd.crosstab(df['Age'], df['Diabetes_binary'])
age_prop_table = age_diabetes_ct.div(age_diabetes_ct.sum(axis=1), axis=0)
age_tiers = {1: '18-24', 2: '25-29', 3: '30-34', 4: '35-39', 5: '40-44', 6: '45-49', 7: '50-54', 8: '55-59', 9: '60-64', 10: '65-69',
11: '70-74', 12: '75-79', 13: '80 or older'}
age_prop_table.plot(kind='bar', stacked=True, colormap='Set1')
plt.title('Proportion of Diabetes Status by Age Tier')
plt.xlabel('Age Tier')
plt.ylabel('Proportion')
plt.xticks(range(len(age_tiers)), list(age_tiers.values()))
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""As age tier increases—particularly past 55—the incidence of pre/diabetes rises substantially. This age effect is consistent with other studies, supporting age-based screening approaches."""

income_diabetes_ct = pd.crosstab(df['Income'], df['Diabetes_binary'])
income_prop_table = income_diabetes_ct.div(income_diabetes_ct.sum(axis=1), axis=0)
income_tiers = {1.0: '<$10,000', 2.0:'<$15,000',
3.0: '<$20,000', 4.0: '$25,000',
5.0: '<$35,000', 6.0: '$<50,000',
7.0: '<$75,000', 8.0: '$75,000 or more'}
plt.figure(figsize=(15, 8))
income_prop_table.plot(kind='bar', stacked=True, colormap='Set1')
plt.title('Proportion of Diabetes Status by Income Tier')
plt.xlabel('Income Tier')
plt.ylabel('Proportion')
plt.xticks(range(len(income_tiers)), list(income_tiers.values()), rotation=65)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""Lower income brackets (especially $10,000–$35,000) show higher diabetes prevalence. Financial barriers might limit access to healthy food, medical care, or consistent follow-ups."""

education_diabetes_ct = pd.crosstab(df['Education'], df['Diabetes_binary'])
prop_table = education_diabetes_ct.div(education_diabetes_ct.sum(axis=1), axis=0)
education_tiers = {1.0: 'Never attended school', 2.0:'Grades 1-8',
3.0: 'Grades 9-11', 4.0: 'Grade 12 or GED',
5.0: 'College 1-3 years', 6.0: 'College 4 years or more'
}
prop_table.plot(kind='bar', stacked=True, colormap='Set1')
plt.title('Proportion of Diabetes Status by Education Tier')
plt.xlabel('Education Tier')
plt.ylabel('Proportion')
plt.xticks(range(len(education_tiers)), list(education_tiers.values()))
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""More prediabetes/diabetes cases are found in people in lower Education Tiers, especially for those who never attended school leading up to Grade 11."""

chi2, p, dof, expected = chi2_contingency(education_diabetes_ct)
print("H0: Education & Diabetes Independent of Each Other | Ha: Education & Diabetes Dependent of Each Other")
print("Chi-square p-value:", p)

if p < 0.5:
    print("\nConclusion: p-value is less than 0.5.")
    print("There is sufficient evidence to reject the null hypothesis and conclude that there is a statistically significant association between Education and Diabetes status.")
else:
    print("\nConclusion: p-value is not less than 0.5.")
    print("There is insufficient evidence to reject the null hypothesis, suggesting that Education and Diabetes status may be independent in this dataset.")

"""Participants with limited formal education (below Grade 11) have a notably higher diabetes prevalence, approaching 41% in some subsets. The chi-square test confirms a statistically significant relationship between education and diabetes. These findings align with research indicating health literacy and educational attainment affect diet, exercise, and healthcare usage."""

insurance_diabetes_ct = pd.crosstab(df['AnyHealthcare'], df['Diabetes_binary'])
insurance_diabetes_ct.plot(kind='bar', stacked=True, colormap='Set1')
plt.title('Counts of Diabetes Status by Insurance Access')
plt.xlabel('Insurance Access')
plt.ylabel('Counts')
plt.xticks([0,1],['No Insurance', 'Has Insurance'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

ins_prop_table = insurance_diabetes_ct.div(insurance_diabetes_ct.sum(axis=1), axis=0)
ins_prop_table

chi2, p, dof, expected = chi2_contingency(insurance_diabetes_ct)
print("H0: Health Insurance & Diabetes Independent of Each Other | Ha: Health Insurance & Diabetes Dependent of Each Other")
print("Chi-square p-value:", p)

if p < 0.5:
    print("\nConclusion: p-value is less than 0.5.")
    print("There is sufficient evidence to reject the null hypothesis and conclude that there is a statistically significant association between Health Insurance and Diabetes status.")
else:
    print("\nConclusion: p-value is not less than 0.5.")
    print("There is insufficient evidence to reject the null hypothesis, suggesting that Health Insurance and Diabetes status may be independent in this dataset.")

"""People with and without insurance both show notable diabetes prevalence (~16% and 13%, respectively), but the chi-square analysis suggests access to insurance is significantly associated with diabetes status."""

cost_diabetes_ct = pd.crosstab(df['NoDocbcCost'], df['Diabetes_binary'])
cost_diabetes_ct.plot(kind='bar', stacked=True, colormap='Set1')
plt.title('Was there a time when you needed to see a doctor but could not because of cost?')
plt.xlabel('Cost Issue')
plt.ylabel('Counts')
plt.xticks([0,1],['No', 'Yes'], rotation=0)
plt.legend(title='Diabetes Status', labels=['No Diabetes','Pre-Diabetes/Diabetes'], bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

cost_prop_table = cost_diabetes_ct.div(cost_diabetes_ct.sum(axis=1), axis=0)
cost_prop_table

"""Among those who avoided doctor visits due to cost, 20% have diabetes—higher than the 15% for those without cost barriers. Financial constraints are thus a critical factor, potentially leading to delayed diagnoses or suboptimal management.

"""

pivot = pd.pivot_table(df, values='Diabetes_binary',
                       index='Education', columns='Income', aggfunc='mean')

plt.figure(figsize=(8,6))
sns.heatmap(pivot, annot=True, cmap='viridis')
plt.title('Diabetes Prevalence by Education and Income')
plt.xlabel('Income Tier')
plt.ylabel('Education Level')
plt.show()

"""Diabetes prevalance are most likely high for those who are in lower tiers of education and income levels, with those who earns less than 25,000 annually and finished Grade 8 and below have up to 41% of diabetes cases. Lower income and lower education levels often limit access to resources such as quality healthcare, nutritious foods, and safe environments for physical activity. These limitations can contribute to higher stress levels and poorer lifestyle choices, all of which increase the risk for developing diabetes.

#### Lifestyle Indicators
"""

smoke_diabetes_ct = pd.crosstab(df['Smoker'], df['Diabetes_binary'])
#prop_table = smoke_diabetes_ct.div(smoke_diabetes_ct.sum(axis=1), axis=0)
smoke_diabetes_ct.plot(kind='bar', stacked=True, colormap='Set2')
plt.title('Count of Diabetes Status by Smoking Status')
plt.xlabel('Smoking Status')
plt.ylabel('Count')
plt.xticks([0, 1], ['Not Smoker', 'Smoker'], rotation=0)
plt.legend(title='HasDiabetes', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

prop_table

"""Smokers (18% diabetes) vs. non-smokers (13% diabetes). This difference points to tobacco use as a potential contributor, aligning with evidence that smoking exacerbates insulin resistance and cardiovascular risk."""

exercise_diabetes_ct = pd.crosstab(df['PhysActivity'], df['Diabetes_binary'])
exercise_prop_table = exercise_diabetes_ct.div(exercise_diabetes_ct.sum(axis=1), axis=0)
exercise_diabetes_ct.plot(kind='bar', stacked=True, colormap='Set2')
plt.title('Proportion of Diabetes Status by Physical Activity')
plt.xlabel('Physical Activity')
plt.ylabel('Counts')
plt.xticks([0, 1], ['No Physical Activity', 'Has Physicial Activity'], rotation=0)
plt.legend(title='HasDiabetes', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

exercise_prop_table

"""Sedentary individuals (23% diabetes) vs. active individuals (13%). The 10% gap underscores exercise as a critical preventive measure. Physical activity is a cornerstone of diabetes management and prevention."""

food_df = df.copy()
food_df['Food_Group'] = food_df.apply(lambda row: 'Both' if row['Fruits'] == 1
                                      and row['Veggies'] == 1 else ('Fruits' if row['Fruits'] == 1 else
                                       ('Vegetables' if row['Veggies'] == 1 else 'Neither')), axis=1)

plt.figure(figsize=(8,4))
sns.barplot(
    data=food_df,
    x='Food_Group',
    y='Diabetes_binary',
    estimator=np.mean,
    ci=95
)
plt.title('Diabetes Prevalence by Combined Food Consumption')
plt.xlabel('Food Consumption Group')
plt.ylabel('Proportion with Diabetes')
plt.ylim(0,1)
plt.show()

ct = pd.crosstab(food_df['Food_Group'], food_df['Diabetes_binary'])

prop_ct = ct.div(ct.sum(axis=1), axis=0)

prop_ct.plot(kind='bar', stacked=True, figsize=(8,4))
plt.title('Stacked Proportion of Diabetes by Food Consumption Group')
plt.xlabel('Food Consumption Group')
plt.ylabel('Proportion')
plt.legend(title='Diabetes_binary', labels=['No Diabetes', 'Diabetes'])
plt.show()

prop_ct

"""People consuming both fruits and vegetables have the lowest diabetes prevalence (~14%), while those consuming only fruits or no produce at all hover around ~20%. A balanced diet with diverse fruits and vegetables appears protective, although the interplay with total calorie intake and other factors warrants further investigation."""

alcohol_diabetes_ct = pd.crosstab(df['HvyAlcoholConsump'], df['Diabetes_binary'])
#prop_table = alcohol_diabetes_ct.div(alcohol_diabetes_ct.sum(axis=1), axis=0)
alcohol_diabetes_ct.plot(kind='bar', stacked=True, colormap='Set2')
plt.title('Proportion of Diabetes Status by Alcohol Consumption')
plt.xlabel('Alcohol Consumption')
plt.ylabel('Counts')
plt.xticks([0, 1], ['No or Low Alcohol Consumption', 'High Alcohol Consumption'], rotation=0)
plt.legend(title='HasDiabetes', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

prop_table

"""Data on heavy drinkers is limited, making it difficult to draw definitive conclusions. Nonetheless, existing literature often flags excessive alcohol intake as a risk factor for metabolic disorders.

## Predictive Modeling

Handle class imbalance using SMOTE
"""

# Define features and target variable
y = df['Diabetes_binary']
X = df.drop(columns=['Diabetes_binary', 'GenHlth', 'Age', 'Education', 'Income'])#since SMOTE can not work with categorical variables

# Splitting data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)

# --- Apply SMOTE to training data ---
smote = SMOTE(random_state=1)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Feature Scaling (after SMOTE to avoid leaking scaling parameters from test set)
scaler = StandardScaler()
X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)
X_test_scaled = scaler.transform(X_test)

def evaluate_model(model, X_test, y_test):
    if isinstance(model, Sequential):  # Check if model is a neural network
        y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
    else:
        y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='macro')
    rec = recall_score(y_test, y_pred, average='macro')
    f1 = f1_score(y_test, y_pred, average='macro')

    return acc, prec, rec, f1

# --- Logistic Regression ---
log_reg_sm = LogisticRegression(solver='liblinear')
log_reg_sm.fit(X_train_resampled_scaled, y_train_resampled)
log_results_sm = evaluate_model(log_reg_sm, X_test_scaled, y_test)

# --- Decision Tree ---
dt_sm = DecisionTreeClassifier(random_state=1)
dt_sm.fit(X_train_resampled, y_train_resampled)
dt_results_sm = evaluate_model(dt_sm, X_test, y_test)

# --- Random Forest ---
rf_sm = RandomForestClassifier(n_estimators=100, random_state=1)
rf_sm.fit(X_train_resampled, y_train_resampled)
rf_results_sm = evaluate_model(rf_sm, X_test, y_test)

# XGBoost
xgb_sm = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1)
xgb_sm.fit(X_train_resampled, y_train_resampled)
xgb_results_sm = evaluate_model(xgb_sm, X_test, y_test)

# Results DataFrame
results_sm = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],
    'Accuracy': [log_results_sm[0], dt_results_sm[0], rf_results_sm[0], xgb_results_sm[0]],
    'Precision': [log_results_sm[1], dt_results_sm[1], rf_results_sm[1], xgb_results_sm[1]],
    'Recall': [log_results_sm[2], dt_results_sm[2], rf_results_sm[2], xgb_results_sm[2]],
    'F1-score': [log_results_sm[3], dt_results_sm[3], rf_results_sm[3], xgb_results_sm[3]]
})

print("\n--- Model Performance Comparison ---")
print(results_sm)

# Identify the best model
best_model_index_sm = results_sm['F1-score'].idxmax()
best_model_name_sm = results_sm.loc[best_model_index_sm, 'Model']
best_model_score_sm = results_sm.loc[best_model_index_sm, 'F1-score']

print(
    f"\nWe choose the {best_model_name_sm} model because it has the highest F1-score "
    f"({best_model_score_sm:.6f}). Below are the key reasons:\n"
    "- The F1-score provides a balanced view of both precision and recall.\n"
    "- This balance is crucial in medical diagnostics, where both false positives "
    "  and false negatives can have serious consequences.\n"
    "- The F1-score works well on skewed datasets, making it more reliable than accuracy.\n"
    "- It ensures that neither precision nor recall is disproportionately favored, "
    "  which is vital in healthcare decisions."
)

"""Handle class imbalance using undersampling"""

# Handle class imbalance using undersampling
df_major_undersampling = df[df['Diabetes_binary'] == 0]
df_minor_undersampling = df[df['Diabetes_binary'] == 1]

df_major_undersampling_downsampled = resample(df_major_undersampling,
                                   replace=False,
                                   n_samples=len(df_minor_undersampling),
                                   random_state=42)

df_balanced_undersampling = pd.concat([df_major_undersampling_downsampled, df_minor_undersampling]).sample(frac=1, random_state=42).reset_index(drop=True)

# Define features and target variable
y = df_balanced_undersampling['Diabetes_binary']
X = df_balanced_undersampling.drop(columns=['Diabetes_binary'])
# Splitting data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# After scaling
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),
                              columns=X_train.columns,
                              index=X_train.index)

X_test_scaled = pd.DataFrame(scaler.transform(X_test),
                             columns=X_test.columns,
                             index=X_test.index)

# Define function to evaluate models
def evaluate_model(model, X_test, y_test):
    if isinstance(model, Sequential):  # Check if model is a neural network
        y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()
    else:
        y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='macro')
    rec = recall_score(y_test, y_pred, average='macro')
    f1 = f1_score(y_test, y_pred, average='macro')

    return acc, prec, rec, f1

# Logistic Regression
log_reg_us = LogisticRegression(solver='liblinear')
log_reg_us.fit(X_train_scaled, y_train)
log_results_us = evaluate_model(log_reg_us, X_test_scaled, y_test)

# Decision Tree
dt_us = DecisionTreeClassifier()
dt_us.fit(X_train, y_train)
dt_results_us = evaluate_model(dt_us, X_test, y_test)

# Random Forest
rf_us = RandomForestClassifier(n_estimators=100)
rf_us.fit(X_train, y_train)
rf_results_us = evaluate_model(rf_us, X_test, y_test)

neg, pos = np.bincount(y_train)
scale_pos_weight = neg / pos

xgb_us = XGBClassifier(use_label_encoder=False, eval_metric='logloss',
                    scale_pos_weight=scale_pos_weight, random_state=1)
xgb_us.fit(X_train_scaled, y_train)
xgb_results_us = evaluate_model(xgb_us, X_test, y_test)

results_undersampling = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],
    'Accuracy': [log_results_us[0], dt_results_us[0], rf_results_us[0], xgb_results_us[0]],
    'Precision': [log_results_us[1], dt_results_us[1], rf_results_us[1], xgb_results_us[1]],
    'Recall': [log_results_us[2], dt_results_us[2], rf_results_us[2], xgb_results_us[2]],
    'F1-score': [log_results_us[3], dt_results_us[3], rf_results_us[3], xgb_results_us[3]]})

print(results_undersampling)

# Identify the model with the highest F1-score
best_model_index_us = results_undersampling['F1-score'].idxmax()
best_model_name_us = results_undersampling.loc[best_model_index_us, 'Model']
best_model_score_us = results_undersampling.loc[best_model_index_us, 'F1-score']

print(
    f"We choose the {best_model_name_us} model because it has the highest F1-score "
    f"({best_model_score_us:.6f}). Below are the key reasons:\n"
    "- The F1-score provides a balanced view of both precision and recall.\n"
    "- This balance is crucial in medical diagnostics, where both false positives "
    "  and false negatives can have serious consequences.\n"
    "- The F1-score works well on skewed datasets, making it more reliable than accuracy.\n"
    "- It ensures that neither precision nor recall is disproportionately favored, "
    "  which is vital in healthcare decisions."
)

print('Handling imbalance by undersampling method')
print('------------------------------------------')
print(results_undersampling)
print('')
print('')
print('Handling imbalance by SMOTE method')
print('------------------------------------------')
print(results_sm)

"""### We Selected Linear Regression as our Primary Model in Undersampling

#### Confusion Matrix
"""

y_pred_log = log_reg_us.predict(X_test_scaled)

c_max_test = pd.DataFrame(confusion_matrix(y_test, y_pred_log, labels=[0,1]),
                                      index=["Actual:0", "Actual:1"], columns=["Pred:0","Pred:1"])
c_max_test

"""### Backward and Forward Selection for Logistic Regression Model"""

def evaluate_model_sfs(model, X_train, X_test, y_train, y_test, model_name, forward_selection):
    # Initialize feature selection (Forward or Backward)
    sfs = SFS(model,
              k_features=(1, X_train.shape[1]),
              forward= forward_selection,  # Choose Forward or Backward
              scoring='f1',
              cv=10)

    # Fit feature selection model
    sfs.fit(X_train, y_train)

    # Store selected feature names
    selected_features = sfs.k_feature_names_
    print(f'\nSelected Features for {model_name}: {selected_features}')

    # Transform data to keep only selected features
    X_train_sfs = sfs.transform(X_train)
    X_test_sfs = sfs.transform(X_test)

    # Train model with selected features
    model.fit(X_train_sfs, y_train)

    # Predict using the trained model
    y_pred = model.predict(X_test_sfs)

    # Compute metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Store results in a dictionary
    metrics = {
        "Model": model_name,
        "Selection Type": "Forward" if forward_selection else "Backward",
        "Accuracy": round(accuracy, 4),
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-score": round(f1, 4),
    }

    return model, selected_features, metrics, sfs

# Run for Logistic Regression with Forward and Backward Selection
log_reg_bw_model, log_reg_bw_features, log_reg_bw_metrics, sfs_bw = evaluate_model_sfs(log_reg_us, X_train_scaled, X_test_scaled, y_train, y_test,
                                                                  "Logistic Regression", forward_selection=False)
log_reg_fw_model, log_reg_fw_features, log_reg_fw_metrics, sfs_fw = evaluate_model_sfs(log_reg_us, X_train_scaled, X_test_scaled, y_train, y_test,
                                                                  "Logistic Regression", forward_selection=True)

log_reg_fw_metrics

# Store all results in a DataFrame for easy comparison
results_df = pd.DataFrame([
    log_reg_fw_metrics,
    log_reg_bw_metrics
])


# Print final comparison table
print("\nFinal Model Comparison:")
print(results_df)

print('Feature Selection for Logistic Regression model(Forward Selection): ', log_reg_fw_features)
print('Feature Selection for Logistic Regression model(Backward Selection): ',log_reg_bw_features)

log_reg_fw_features

np.set_printoptions(suppress=True)

original_features = X_train.columns.tolist()
original_features

"""### Testing Model Prediction"""

# Making predictions for patient with
#'HighBP':1, 'HighChol':1, 'CholCheck':1, 'BMI':28, 'Smoker':0, 'Stroke':1 'HeartDiseaseorAttack':1, 'PhysActivity':1, 'Fruit':0, 'Veggies':0,
#'HvyAlcoholConsump':0, 'AnyHealthcare':1, 'NoDocbcCost: 0','GenHlth':4, 'MenHlth':5', PhysHlth':15, 'DiffWalk':1, 'Sex':1, 'Age: 5','Education: 5','Income: 5'

new_sample_values = [[1, 1, 1, 28, 0, 1, 1, 1, 0,0,
                      0, 1, 0, 4, 5, 15, 1, 1,
                      5, 5, 5]]

new_sample_raw = pd.DataFrame(new_sample_values, columns=original_features)

# Scale the new sample using the same scaler
new_sample_scaled = pd.DataFrame(scaler.transform(new_sample_raw),
                                 columns=original_features)

# Apply the feature selection transformation to get only the selected features
new_sample_sfs = sfs_fw.transform(new_sample_scaled)

# Predict the probability
probabilities = log_reg_us.predict_proba(new_sample_sfs)

print("Probabilities:", probabilities)

outcome = log_reg_us.predict(new_sample_sfs)
print("Outcome:", outcome)

"""### Prescriptive Modeling"""

def prescribe_interventions(input_data, risk_thredshold=None):
    # Set risk thresholds
    if risk_thredshold is None:
        risk_thredshold = {"low": 0.3, "medium": 0.5}


    # Build the new sample as a DataFrame using all original features
    original_features = X_train.columns.tolist()
    input_df = pd.DataFrame([input_data], columns=original_features)
    # Align the new sample so it has all the expected original features, fill missing values with 0
    input_aligned = input_df.reindex(columns=original_features, fill_value=0)

    # Scale the new sample using the same scaler as training
    # The scaler was fitted on data with the full set (21) of original features.
    new_sample_scaled = pd.DataFrame(scaler.transform(input_aligned),
                                     columns=original_features,
                                     index=input_aligned.index)

    # Transform using the Sequential Feature Selector to reduce the sample from 21 features to the selected features.
    new_sample_sfs = sfs_fw.transform(new_sample_scaled)

    # Get the predicted risk using the trained model
    risk = log_reg_us.predict_proba(new_sample_sfs)[:, 1][0]

    # Categorize risk
    if risk < risk_thredshold["low"]:
        risk_category = "Low"
    elif risk < risk_thredshold["medium"]:
        risk_category = "Medium"
    else:
        risk_category = "High"

    # Risk-Based Recommendations
    recommendation = []
    if risk_category == "Low":
        recommendation.append(
            "Your diabetes risk is low. Please maintain a healthy lifestyle, engage in frequent physical activity,\n"
            "and follow regular check-ups to promote your overall well-being.")
    elif risk_category == "Medium":
        recommendation.append(
            "Your diabetes risk is medium. Please make modifications in your lifestyle and diets to mitigate this risk.\n"
            "A screening or check-up with your Primary Care Physician is highly recommended for early detection of potential health issues.")
    else:
        recommendation.append(
            "Your diabetes risk is high. Please consult with medical professionals accordingly.\n"
            "In the meantime, consider managing your risk by modifying your lifestyle, diets, and physical activities.")

    # --- Prescriptive Rules (for Medium or High risk) ---
    if risk_category in ["Medium", "High"]:
        if input_data.get('BMI', 0) > 25:
            recommendation.append(
                "Your BMI indicates overweight or obese status, which increases your risk of developing diabetes.\n"
                "Consider following a weight management plan, such as managing your diet intake and introducing regular exercise to your daily routine.")
        if input_data.get('PhysActivity', 0) == 0:
            recommendation.append(
                "Physical activity is fundamental in diabetes management.\n"
                "The American Diabetes Association recommends at least 150 minutes of moderate-to-vigorous aerobic activity per week.\n"
                "Consider scheduling short, regular walks or other activities to build up your routine.")
        if input_data.get('Fruits', 0) == 1 and input_data.get('Veggies', 0) == 0:
            recommendation.append(
                "While fruits are a healthy source of nutrients, excessive fruit intake (over 2 servings/day) without adequate vegetables\n"
                "could result in higher energy intake. Consider incorporating more vegetables along with fruits for a balanced diet.")
        if input_data.get('Fruits', 0) == 0 and input_data.get('Veggies', 0) == 0:
            recommendation.append(
                "A nutritious, balanced diet is essential for blood sugar management.\n"
                "Consider adding fruits—especially berries—and a variety of vegetables, including dark green and cruciferous options, to your meals.")
        if input_data.get('Smoker', 0) == 1:
            recommendation.append(
                "As smoking increases the risk of type 2 diabetes by 30-40%, quitting smoking can contribute to better blood sugar control.\n"
                "Discuss available nicotine replacement therapies with a healthcare provider.")
        if input_data.get('HighBP', 0) == 1:
            recommendation.append(
                "For those with high blood pressure, following the DASH (Dietary Approaches to Stop Hypertension) plan can help mitigate diabetes risk.\n"
                "This includes limiting sodium intake and focusing on nutrient-rich foods.")

    return risk, recommendation

example_patient = {
    'HighBP': 1,
    'HighChol': 1,
    'CholCheck': 1,
    'BMI': 28,
    'Smoker': 0,
    'Stroke': 1,
    'HeartDiseaseorAttack': 1,
    'PhysActivity': 1,
    'Fruits': 1,
    'Veggies': 1,
    'HvyAlcoholConsump': 0,
    'AnyHealthcare': 1,
    'NoDocbcCost': 0,
    'GenHlth': 4,
    'MentHlth': 5,
    'PhysHlth': 5,
    'DiffWalk': 0,
    'Sex': 1,
    'Age': 5,
    'Education': 5,
    'Income': 5
}

predicted_risk, suggested_actions = prescribe_interventions(
    example_patient,
    risk_thredshold={"low": 0.3, "medium": 0.5})

print("Predicted Diabetes Risk: {:.1%}".format(predicted_risk))
print("Recommended Interventions:")
for action in suggested_actions:
    print("-", action)
